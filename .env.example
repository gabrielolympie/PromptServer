## Docker
DOCKER_USERNAME=YOUR_DOCKER_USER_NAME
APPLICATION_NAME=prompt_server

PORT=8080 ## define exposition port here, only for local use, for docker directly edit the docker file
API_TOKEN=YOUR_API_TOKEN # this is used to secure the query with a simple token verification, not enforced yet.
API_TOKEN_TIMEOUT=500

## Path
PROMPT_PATH="prompts"

## Logfire
LOGFIRE_TOKEN=YOUR_LOGFIRE_TOKEN # commment to disable logfire loging

## URL REDEFINITION
# OPENAI_API_BASE=http://localhost:5000/v1 ## if this is uncommented, any model with prefix openai/ will be redirected toward this url

OPENAI_API_KEY=YOUR_API_KEY
GEMINI_API_KEY=YOUR_API_KEY
MISTRAL_API_KEY=YOUR_API_KEY

## MODELS DEFINITIONS (these model can be chosen from within prompts.)
## To be noted, but model can also be defined directly from the prompt
GENERAL_PURPOSE_MODEL="gemini/gemini-2.0-flash" ## example google model
FALLBACK_MODEL="gemini-1.5-flash-8b" ## fallback models are used when base model does not work

# GENERAL_PURPOSE_MODEL="mistral/mistral-small-latest" ## example google model
# GENERAL_PURPOSE_MODEL="openai/gpt-4" ## example openai model
# OPENAI_MODEL_NAME=openai/exllamav2 ## example local model

THINKING_MODEL="gemini/gemini-2.0-flash-thinking-exp-01-21"
