{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1567893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from clients.prompt_client import PromptClient\n",
    "import json\n",
    "\n",
    "client = PromptClient(\n",
    "    base_url=f\"{os.getenv('BASE_URL')}/{os.getenv('APPLICATION_NAME')}/v1\",\n",
    "    api_key=os.getenv('API_TOKEN')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c6928",
   "metadata": {},
   "source": [
    "## First, launch the server, according to whats written in the readme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aaafb8",
   "metadata": {},
   "source": [
    "## Understanding prompt structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef45eccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Let me explain how prompt files work in a way that should be helpful for you as an LLM engineer.\n",
      "\n",
      "### Overview of Prompt Files\n",
      "\n",
      "Prompt files are a structured way to define complex prompts for language models using a markdown file format. This makes it easier to read, iterate, and manage your prompts. The structure is divided into sections using triple dashes (`---`), with the first section always being the configuration.\n",
      "\n",
      "### Configuration Section\n",
      "\n",
      "The configuration section is a YAML object that must include the following fields:\n",
      "\n",
      "1. **Mirascope Call Params**: Parameters for the Mirascope call. You can refer to the [Mirascope documentation](https://mirascope.com/docs/mirascope/learn/calls) for more details.\n",
      "\n",
      "2. **Model**: You can define a model here using Litellm syntax or use one of the standard models defined in environment variables.\n",
      "\n",
      "3. **Stream**: Whether to stream the response (always set to `true`).\n",
      "\n",
      "4. **Json Mode**: Whether to use JSON mode (not supported yet).\n",
      "\n",
      "5. **Tools**: A list of tools accessible to the LLM. Tools should be imported in the `clients/mirascope.py` file to work properly. Check the [Mirascope documentation](https://mirascope.com/docs/mirascope/learn/tools) for more information.\n",
      "\n",
      "6. **Call Params**: Parameters passed to the LLM provider. Refer to the [Litellm documentation](https://docs.litellm.ai/docs) for more details.\n",
      "\n",
      "7. **Retry**: Number of retry attempts.\n",
      "\n",
      "8. **Fallback**: Fallback model to use if the call fails.\n",
      "\n",
      "9. **Tool Recursion Depth**: Limit the total number of tool calls that can be made in a single call.\n",
      "\n",
      "10. **Parse Objects**: Whether to parse objects from the response, enabling the return of not only text but also objects written by the LLM in the response.\n",
      "\n",
      "11. **Input Params**: Input parameters of the prompt, used to document the OpenAPI route auto-generated from the prompt file.\n",
      "\n",
      "12. **Tags**: A list of tags to categorize the prompt, used for Logfire filtering.\n",
      "\n",
      "### Prompt Sections\n",
      "\n",
      "The next sections define the prompt itself and the messages of the conversation. You use standard Mirascope keywords for roles: `USER`, `ASSISTANT`, `SYSTEM`, and `MESSAGES`.\n",
      "\n",
      "- **MESSAGES Role**: Defines the history of the conversation. This will be replaced by the actual history of the conversation when the prompt is called.\n",
      "- **Other Roles**: Standard conversational roles used to define the prompt itself.\n",
      "\n",
      "### Example Structure\n",
      "\n",
      "Here’s a simple example of what a prompt file might look like:\n",
      "\n",
      "```yaml\n",
      "---\n",
      "mirascope_call_params:\n",
      "  model: gpt-4\n",
      "  stream: true\n",
      "  tools: [tool1, tool2]\n",
      "  call_params:\n",
      "    temperature: 0.7\n",
      "  retry: 3\n",
      "  fallback: gpt-3.5-turbo\n",
      "  tool_recursion_depth: 5\n",
      "  parse_objects: true\n",
      "  input_params:\n",
      "    param1: string\n",
      "    param2: integer\n",
      "  tags: [tag1, tag2]\n",
      "---\n",
      "\n",
      "SYSTEM:\n",
      "You are a helpful assistant.\n",
      "\n",
      "USER:\n",
      "{input}\n",
      "\n",
      "ASSISTANT:\n",
      "Here is the response based on the input.\n",
      "\n",
      "MESSAGES:\n",
      "{history}\n",
      "```\n",
      "\n",
      "### Additional Features\n",
      "\n",
      "- **Multimodal Input**: Supported, allowing for various types of input beyond text.\n",
      "- **Streaming Tool Calls**: Supported, enabling real-time interaction with tools.\n",
      "- **Complete Mirascope Features**: All native Mirascope features are supported. Refer to the [Mirascope documentation](https://mirascope.com/docs/mirascope/learn/prompts) for more details.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Prompt files provide a structured and flexible way to define complex prompts, making it easier to manage and iterate on your LLM interactions. By using YAML for configuration and markdown for the prompt itself, you can create clear and maintainable prompt definitions.\n"
     ]
    }
   ],
   "source": [
    "text, objects, tools = client.call(\n",
    "    input_data={'history':[], 'persona': 'A llm engineer willing to learn'},\n",
    "    route=\"/prompts/readme\"\n",
    ")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bdf5c0",
   "metadata": {},
   "source": [
    "## Of course, you can also stream the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6396ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Let me explain how prompt files work in a way that should be helpful for you as an LLM engineer.\n",
      "\n",
      "### Overview of Prompt Files\n",
      "\n",
      "Prompt files are a structured way to define complex prompts for language models using a markdown file format. This makes it easier to read, iterate, and manage your prompts. The structure is divided into sections using triple dashes (`---`), with the first section always being the configuration.\n",
      "\n",
      "### Configuration Section\n",
      "\n",
      "The configuration section is a YAML object that must include the following fields:\n",
      "\n",
      "1. **Mirascope Call Params**: Parameters for the Mirascope call. You can refer to the [Mirascope documentation](https://mirascope.com/docs/mirascope/learn/calls) for more details.\n",
      "\n",
      "2. **Model**: You can define a model here using Litellm syntax or use one of the standard models defined in environment variables.\n",
      "\n",
      "3. **Stream**: Whether to stream the response (always set to `true`).\n",
      "\n",
      "4. **Json Mode**: Whether to use JSON mode (not supported yet).\n",
      "\n",
      "5. **Tools**: A list of tools accessible to the LLM. Tools should be imported in the `clients/mirascope.py` file to work properly. Check the [Mirascope documentation](https://mirascope.com/docs/mirascope/learn/tools) for more information.\n",
      "\n",
      "6. **Call Params**: Parameters passed to the LLM provider. Refer to the [Litellm documentation](https://docs.litellm.ai/docs) for more details.\n",
      "\n",
      "7. **Retry**: Number of retry attempts.\n",
      "\n",
      "8. **Fallback**: Fallback model to use if the call fails.\n",
      "\n",
      "9. **Tool Recursion Depth**: Limit the total number of tool calls that can be made in a single call.\n",
      "\n",
      "10. **Parse Objects**: Whether to parse objects from the response. This enables returning not only text but also objects written by the LLM in the response.\n",
      "\n",
      "11. **Input Params**: Input parameters of the prompt, used to document the OpenAPI route auto-generated from the prompt file.\n",
      "\n",
      "12. **Tags**: A list of tags to categorize the prompt, used for Logfire filtering.\n",
      "\n",
      "### Prompt Sections\n",
      "\n",
      "After the configuration, the next sections define the prompt itself and the messages of the conversation. You can use standard Mirascope keywords for roles: `USER`, `ASSISTANT`, `SYSTEM`, and `MESSAGES`.\n",
      "\n",
      "- **MESSAGES Role**: Used to define the history of the conversation. It will be replaced by the actual history of the conversation when the prompt is called.\n",
      "- **Other Roles**: Standard conversational roles used to define the prompt itself.\n",
      "\n",
      "### Example Structure\n",
      "\n",
      "Here’s an example of how a prompt file might look:\n",
      "\n",
      "```yaml\n",
      "---\n",
      "# Configuration\n",
      "model: gpt-4\n",
      "stream: true\n",
      "tools: [tool1, tool2]\n",
      "call_params: {temperature: 0.7}\n",
      "retry: 3\n",
      "fallback: gpt-3.5-turbo\n",
      "tool_recursion_depth: 5\n",
      "parse_objects: true\n",
      "input_params:\n",
      "  - name: user_input\n",
      "    type: string\n",
      "    description: The input from the user\n",
      "tags: [example, demo]\n",
      "\n",
      "# Prompt\n",
      "SYSTEM: You are a helpful assistant.\n",
      "USER: {user_input}\n",
      "ASSISTANT: I will respond to your input.\n",
      "MESSAGES: {history}\n",
      "```\n",
      "\n",
      "### Additional Features\n",
      "\n",
      "- **Multimodal Input**: Supported, allowing for various types of input beyond text.\n",
      "- **Streaming Tool Calls**: Supported, enabling real-time interaction with tools.\n",
      "- **Complete Mirascope Features**: All native Mirascope features are supported. Refer to the [Mirascope documentation](https://mirascope.com/docs/mirascope/learn/prompts) for more details.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Prompt files provide a structured and flexible way to define complex prompts, making it easier to manage and iterate on your LLM interactions. By using YAML for configuration and markdown for the prompt itself, you can create clear and maintainable prompt definitions."
     ]
    }
   ],
   "source": [
    "response = client.stream(\n",
    "    input_data={'history':[], 'persona': 'A llm engineer willing to learn'},\n",
    "    route=\"/prompts/readme\"\n",
    ")\n",
    "\n",
    "for elt in response:\n",
    "    if elt['format'] == 'text':\n",
    "        print(elt['content'], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa091044",
   "metadata": {},
   "source": [
    "## Tool call? Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11c8a8",
   "metadata": {},
   "source": [
    "Tools are defined as python function in /src/tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e2c16",
   "metadata": {},
   "source": [
    "build a simple square tool, to define it, we create the file /src/tools/calculator\n",
    "\n",
    "```python\n",
    "async def square(n: float) -> float:\n",
    "    \"\"\"Takes in a number n, returns the square of n\n",
    "\n",
    "    Args:\n",
    "       n (float): The number to be squared.\n",
    "    \"\"\"\n",
    "    return n**2\n",
    "```\n",
    "\n",
    "then simply add it to the export in the __init__.py of the tool folder\n",
    "\n",
    "```python\n",
    "from src.tools.calculator import square\n",
    "from src.tools.llm_planner import llm_planner\n",
    "from src.tools.retrieval import search_movie_bm25\n",
    "\n",
    "__all__ = [\"square\", \"llm_planner\", \"search_movie_bm25\"]\n",
    "```\n",
    "\n",
    "then restart the server, and you can define the tool directly by referencing it in your prompt.\n",
    "\n",
    "Case in point : the square prompt in /prompts/square.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e95fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ TOOL CALL ************\n",
      "<tool_call>\n",
      "### NAME: square\n",
      "### ARGUMENTS: (\"n\": 4.0)\n",
      "### RESULT: 16.0\n",
      "</tool_call>\n",
      "************\n",
      "The square of 4.0 is 16.0"
     ]
    }
   ],
   "source": [
    "response = client.stream(\n",
    "    input_data={'history':[], 'number': 4},\n",
    "    route=\"/prompts/square\"\n",
    ")\n",
    "\n",
    "for elt in response:\n",
    "    if elt['format'] == 'text':\n",
    "        print(elt['content'], end=\"\")\n",
    "    elif elt['format'] == \"tool\":\n",
    "        print(\"************ TOOL CALL ************\")\n",
    "        print(elt['content'])\n",
    "        print(\"************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0fb8b",
   "metadata": {},
   "source": [
    "## Streaming objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf71c7",
   "metadata": {},
   "source": [
    "In many cases, you can find yourself needing to structure json or yaml with a llm.\n",
    "Instead of using the json mode, the idea here is to be able to parse directly objects from the stream, enabling more interactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d516056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ TOOL CALL ************\n",
      "<tool_call>\n",
      "### NAME: square\n",
      "### ARGUMENTS: (\"n\": 4.0)\n",
      "### RESULT: 16.0\n",
      "</tool_call>\n",
      "*************************************\n",
      "\n",
      "```yaml\n",
      "input: 4.0\n",
      "output: 16.0\n",
      "rational: The square of 4.0 is calculated by multiplying 4.0 by itself, resulting in 16.0.\n",
      "\n",
      "************ Object parsed ************\n",
      "{'input': '4.0', 'output': '16.0', 'rational': 'The square of 4.0 is calculated by multiplying 4.0 by itself, resulting in 16.0.'}\n",
      "*************************************\n",
      "\n",
      "```\n",
      "\n",
      "I have squared the number 4.0 and obtained the result 16.0."
     ]
    }
   ],
   "source": [
    "response = client.stream(\n",
    "    input_data={'history':[], 'number': 4},\n",
    "    route=\"/prompts/square_object\"\n",
    ")\n",
    "\n",
    "for elt in response:\n",
    "    if elt['format'] == 'text':\n",
    "        print(elt['content'], end=\"\")\n",
    "    elif elt['format'] == \"tool\":\n",
    "        print(\"\\n************ TOOL CALL ************\")\n",
    "        print(elt['content'])\n",
    "        print(\"*************************************\\n\")\n",
    "    elif elt['format'] == \"object\":\n",
    "        print(\"\\n************ Object parsed ************\")\n",
    "        print(json.loads(elt['content']))\n",
    "        print(\"*************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef993373",
   "metadata": {},
   "source": [
    "## Wanna batch? Lets go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b2a5055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   1 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    1.7s remaining:    2.5s\n",
      "[Parallel(n_jobs=5)]: Done   3 out of   5 | elapsed:    1.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Il pleut des cordes', [], []),\n",
       " ('El sol brilla con fuerza', [], []),\n",
       " ('Ich liebe Fußball zu spielen', [], []),\n",
       " ('La pizza è deliziosa', [], []),\n",
       " ('A praia é bonita', [], [])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_translate = [\n",
    "    {\"target_language\":\"french\", \"text\":\"It's raining cats and dogs\"},\n",
    "    {\"target_language\":\"spanish\", \"text\":\"The sun is shining brightly\"},\n",
    "    {\"target_language\":\"german\", \"text\":\"I love playing football\"},\n",
    "    {\"target_language\":\"italian\", \"text\":\"The pizza is delicious\"},\n",
    "    {\"target_language\":\"portuguese\", \"text\":\"The beach is beautiful\"},\n",
    "]\n",
    "\n",
    "results = client.batch(\n",
    "    input_data=sentence_to_translate,\n",
    "    route=\"/prompts/translate\",\n",
    "    n_jobs=5,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9547781",
   "metadata": {},
   "source": [
    "## Bringing vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a357d9",
   "metadata": {},
   "source": [
    "Prompt server is natively multimodal, just send your url or base64 data, use a compatible provider, and you're good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13199b40",
   "metadata": {},
   "source": [
    "Example: let's build and advanced flux Kontext prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbddf7a",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "  <img src=\"https://www.science.org/do/10.1126/science.aaw4076/full/dolphin_16x9_2-1644908628810.jpg\" alt=\"Dolphin\" style=\"max-width:512px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a047c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. UNDERSTAND: Carefully analyze the simple instruction provided by the user. Identify the main objective and any specific details mentioned.\n",
      "\n",
      "The main objective is to create a logo based on the provided image of two dolphins leaping out of the water. The instruction is quite simple and lacks specific details about the desired style, composition, or elements to preserve or modify.\n",
      "\n",
      "### 2. DESCRIPTION: Use the description of the base image to provide context for the modifications. This helps in understanding what elements need to be preserved or changed.\n",
      "\n",
      "The base image features two dolphins leaping out of the water. The dolphins are in mid-air, with water splashing around them. The background is a clear blue ocean with a light blue sky. The dolphins are the central focus of the image, and their dynamic pose suggests movement and energy.\n",
      "\n",
      "### 3. DETAILS: If the users instruction is vague, use creative imagination to infer necessary details. This may involve expanding on the instruction to include specific elements that should be modified or preserved.\n",
      "\n",
      "Since the instruction is vague, we need to infer details about the desired logo. A logo based on this image could involve simplifying the dolphins' forms to make them more suitable for a logo. We should preserve the dynamic pose and the sense of movement. The logo could be stylized to be more abstract or simplified, while still being recognizable as dolphins. The color scheme could be inspired by the original image, using shades of blue and gray.\n",
      "\n",
      "### 4. IMAGINE: Imagine the scene with extreme details, every points from the scene should be explicited without ommiting anything.\n",
      "\n",
      "The scene features two dolphins leaping out of the water. The dolphins are in mid-air, with their bodies arched gracefully. The water around them is splashing, creating a dynamic and energetic atmosphere. The background is a clear blue ocean that stretches out to the horizon, meeting a light blue sky. The dolphins are the central focus, with their sleek, streamlined bodies glistening in the sunlight. The water droplets around them catch the light, adding sparkles and highlights to the scene. The overall mood is one of joy and freedom, capturing the essence of the dolphins' playful nature.\n",
      "\n",
      "### 5. EXTRAPOLATE: Describe in detail every elements from the identity of the first image that are missing. Propose description for how they should look like.\n",
      "\n",
      "The identity of the first image includes the dynamic pose of the dolphins, the splashing water, and the clear blue ocean and sky. To create a logo, we need to simplify these elements while preserving their essence. The dolphins should be stylized to be more abstract, with simplified forms that are easily recognizable. The water splashes can be represented by abstract shapes or lines that suggest movement. The background can be simplified to a solid color or gradient that reflects the original color scheme.\n",
      "\n",
      "### 6. SCALE: Assess what should be the relative scale of the elements added compared with the initial image.\n",
      "\n",
      "In the logo, the dolphins should be the central focus, similar to their prominence in the original image. The water splashes and background elements should be scaled down or simplified to support the main subjects without overwhelming them. The overall composition should be balanced, with the dolphins taking up a significant portion of the logo's space.\n",
      "\n",
      "### 7. FIRST DRAFT: Write the prompt using clear, specific, and creative instructions. Ensure that the prompt includes:\n",
      "\n",
      "* Specific modifications or transformations required.\n",
      "* Details on what elements should remain unchanged.\n",
      "* Clear and unambiguous language to guide Kontext effectively.\n",
      "\n",
      "**Optimized Kontext Prompt**:\n",
      "```yaml\n",
      "prompt: \"Transform the image into a logo while maintaining the dynamic pose and playful energy of the two dolphins. Simplify the dolphins' forms to make them more abstract and recognizable as a logo. Preserve the sense of movement and energy by incorporating abstract shapes or lines to represent the water splashes. Use a color scheme inspired by the original image, with shades of blue and gray. Ensure the dolphins are the central focus, with a balanced composition that reflects their playful nature. Maintain the overall mood of joy and freedom.\"\n",
      "\n",
      "************ Object parsed ************\n",
      "{'prompt': \"Transform the image into a logo while maintaining the dynamic pose and playful energy of the two dolphins. Simplify the dolphins' forms to make them more abstract and recognizable as a logo. Preserve the sense of movement and energy by incorporating abstract shapes or lines to represent the water splashes. Use a color scheme inspired by the original image, with shades of blue and gray. Ensure the dolphins are the central focus, with a balanced composition that reflects their playful nature. Maintain the overall mood of joy and freedom.\"}\n",
      "*************************************\n",
      "\n",
      "```\n",
      "\n",
      "### 8. CRITIC: Assess each evaluation point one by one listing strength and weaknesses of the first draft one by one. Formulate each in a list of bullet point (so two list per eval criterion)\n",
      "\n",
      "**Clarity**:\n",
      "- Strengths:\n",
      "  - The prompt clearly states the main objective of transforming the image into a logo.\n",
      "  - It specifies the need to maintain the dynamic pose and playful energy of the dolphins.\n",
      "  - The instructions are straightforward and easy to understand.\n",
      "- Weaknesses:\n",
      "  - The prompt could be more specific about the desired style of the logo (e.g., minimalist, abstract, or cartoonish).\n",
      "  - It lacks details on how to handle the background and water splashes in the logo.\n",
      "\n",
      "**Specificity**:\n",
      "- Strengths:\n",
      "  - The prompt mentions simplifying the dolphins' forms and using a color scheme inspired by the original image.\n",
      "  - It specifies the need to preserve the sense of movement and energy.\n",
      "- Weaknesses:\n",
      "  - The prompt does not provide specific details on the size or placement of the dolphins in the logo.\n",
      "  - It lacks specific instructions on how to represent the water splashes and background.\n",
      "\n",
      "**Preservation**:\n",
      "- Strengths:\n",
      "  - The prompt emphasizes preserving the dynamic pose and playful energy of the dolphins.\n",
      "  - It mentions maintaining the overall mood of joy and freedom.\n",
      "- Weaknesses:\n",
      "  - The prompt does not explicitly state what elements of the background should be preserved or modified.\n",
      "  - It lacks specific instructions on how to handle the water splashes and their representation in the logo.\n",
      "\n",
      "**Creativity**:\n",
      "- Strengths:\n",
      "  - The prompt encourages creative interpretation by suggesting abstract shapes or lines for the water splashes.\n",
      "  - It allows for creative freedom in simplifying the dolphins' forms.\n",
      "- Weaknesses:\n",
      "  - The prompt could be more creative in suggesting alternative styles or compositions for the logo.\n",
      "  - It lacks specific ideas on how to make the logo more unique or memorable.\n",
      "\n",
      "**Best_Practices**:\n",
      "- Strengths:\n",
      "  - The prompt follows the best practice of being specific and explicit.\n",
      "  - It includes preservation instructions for important elements.\n",
      "  - It uses clear and unambiguous language.\n",
      "- Weaknesses:\n",
      "  - The prompt could be more detailed in describing the desired style and composition.\n",
      "  - It lacks specific instructions on how to handle the background and water splashes.\n",
      "\n",
      "**Staticity**:\n",
      "- Strengths:\n",
      "  - The prompt focuses on a static image and does not involve any motion or time-related changes.\n",
      "- Weaknesses:\n",
      "  - The prompt could be more explicit in describing the static nature of the logo.\n",
      "\n",
      "### 9. FEEDBACK: Based on the critic, make a list of the improvements to bring to the prompt, in an action oriented way.\n",
      "\n",
      "- Specify the desired style of the logo (e.g., minimalist, abstract, or cartoonish).\n",
      "- Provide more details on the size and placement of the dolphins in the logo.\n",
      "- Explicitly state what elements of the background should be preserved or modified.\n",
      "- Include specific instructions on how to represent the water splashes and background.\n",
      "- Suggest alternative styles or compositions for the logo to enhance creativity.\n",
      "- Be more explicit in describing the static nature of the logo.\n",
      "\n",
      "### 9. FINAL : Write the final prompt in a plain text snippet\n",
      "\n",
      "**Optimized Kontext Prompt**:\n",
      "```yaml\n",
      "prompt: \"Transform the image into a minimalist, abstract logo while maintaining the dynamic pose and playful energy of the two dolphins. Simplify the dolphins' forms to make them more recognizable as a logo, ensuring they are the central focus. Preserve the sense of movement and energy by incorporating abstract shapes or lines to represent the water splashes. Use a color scheme inspired by the original image, with shades of blue and gray. Ensure the dolphins are prominently placed in the center of the logo, with a balanced composition that reflects their playful nature. Simplify the background to a solid blue color, maintaining the overall mood of joy and freedom. Make sure the logo is static and does not involve any motion or time-related changes.\"\n",
      "\n",
      "************ Object parsed ************\n",
      "{'prompt': \"Transform the image into a minimalist, abstract logo while maintaining the dynamic pose and playful energy of the two dolphins. Simplify the dolphins' forms to make them more recognizable as a logo, ensuring they are the central focus. Preserve the sense of movement and energy by incorporating abstract shapes or lines to represent the water splashes. Use a color scheme inspired by the original image, with shades of blue and gray. Ensure the dolphins are prominently placed in the center of the logo, with a balanced composition that reflects their playful nature. Simplify the background to a solid blue color, maintaining the overall mood of joy and freedom. Make sure the logo is static and does not involve any motion or time-related changes.\"}\n",
      "*************************************\n",
      "\n",
      "```"
     ]
    }
   ],
   "source": [
    "image_url = \"https://www.science.org/do/10.1126/science.aaw4076/full/dolphin_16x9_2-1644908628810.jpg\"\n",
    "edit_instruction=\"I want to make a logo based on this image\"\n",
    "\n",
    "\n",
    "response = client.stream(\n",
    "    input_data={'history':[], 'image': image_url, 'prompt':edit_instruction},\n",
    "    route=\"/prompts/kontext\"\n",
    ")\n",
    "\n",
    "for elt in response:\n",
    "    if elt['format'] == 'text':\n",
    "        print(elt['content'], end=\"\")\n",
    "    elif elt['format'] == \"tool\":\n",
    "        print(\"\\n************ TOOL CALL ************\")\n",
    "        print(elt['content'])\n",
    "        print(\"*************************************\\n\")\n",
    "    elif elt['format'] == \"object\":\n",
    "        print(\"\\n************ Object parsed ************\")\n",
    "        print(json.loads(elt['content']))\n",
    "        print(\"*************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008d2cf-dce7-480a-8d28-796d09927454",
   "metadata": {},
   "source": [
    "## Promptception : prompt as tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723243e-2327-4caa-b675-d54e5a71945c",
   "metadata": {},
   "source": [
    "The tool llm planner is an example of how to use a prompt as tool inside an other prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cae2317c-f812-436a-b530-6de89b776468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ TOOL CALL ************\n",
      "<tool_call>\n",
      "### NAME: llm_planner\n",
      "### ARGUMENTS: (\"tools\": \"[(\\\"name\\\": \\\"square\\\", \\\"tool\\\": (\\\"square\\\": (\\\"n\\\": (\\\"description\\\": \\\"The number to be squared.\\\"))))]\", \"task\": \"Compute the power four of a number provided by the user, using all the tools at your disposal\")\n",
      "### RESULT: ```plan\n",
      "1. Perform action 1 using square\n",
      "2. Perform action 2 using square\n",
      "Provide the final answer\n",
      "```\n",
      "</tool_call>\n",
      "*************************************\n",
      "\n",
      "\n",
      "************ TOOL CALL ************\n",
      "<tool_call>\n",
      "### NAME: square\n",
      "### ARGUMENTS: (\"n\": 4)\n",
      "### RESULT: 16.0\n",
      "</tool_call>\n",
      "*************************************\n",
      "\n",
      "\n",
      "************ TOOL CALL ************\n",
      "<tool_call>\n",
      "### NAME: square\n",
      "### ARGUMENTS: (\"n\": 16)\n",
      "### RESULT: 256.0\n",
      "</tool_call>\n",
      "*************************************\n",
      "\n",
      "The power four of 4.0 is 256.0."
     ]
    }
   ],
   "source": [
    "response = client.stream(\n",
    "    input_data={'history':[], 'number': 4},\n",
    "    route=\"/prompts/double_square_plan\"\n",
    ")\n",
    "\n",
    "for elt in response:\n",
    "    if elt['format'] == 'text':\n",
    "        print(elt['content'], end=\"\")\n",
    "    elif elt['format'] == \"tool\":\n",
    "        print(\"\\n************ TOOL CALL ************\")\n",
    "        print(elt['content'])\n",
    "        print(\"*************************************\\n\")\n",
    "    elif elt['format'] == \"object\":\n",
    "        print(\"\\n************ Object parsed ************\")\n",
    "        print(json.loads(elt['content']))\n",
    "        print(\"*************************************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9861d-8397-4bf7-b576-11dde1e386f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptserver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
